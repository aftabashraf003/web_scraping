{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text mining of Pubmed Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "\n",
    "To find the most appropriate journal for a researcher to publish, based on the keywords and the title of his article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "\n",
    "The dataset is obtained through scrapping of Information obtained from the pubmed Database\n",
    "\n",
    "It contains the following columns:\n",
    "\n",
    "1. Title of the Paper\n",
    "2. Authors of the Paper\n",
    "3. Name of the Journal Published\n",
    "4. Keywords of the article\n",
    "5. Full citation\n",
    "6. Year Published"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /home/ibab/anaconda3/lib/python3.8/site-packages (1.8.1)\r\n",
      "Requirement already satisfied: pillow in /home/ibab/anaconda3/lib/python3.8/site-packages (from wordcloud) (7.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/ibab/anaconda3/lib/python3.8/site-packages (from wordcloud) (1.18.5)\r\n",
      "Requirement already satisfied: matplotlib in /home/ibab/anaconda3/lib/python3.8/site-packages (from wordcloud) (3.3.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ibab/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ibab/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ibab/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ibab/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\r\n",
      "Requirement already satisfied: six in /home/ibab/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ibab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ibab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ibab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.express as px\n",
    "import seaborn as sns  \n",
    "!pip install wordcloud\n",
    "from wordcloud import STOPWORDS, WordCloud #Libraries for Visualisation\n",
    "\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')  #Libraries for Processing of Language\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import HashingVectorizer,TfidfVectorizer #Preprocessing the models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>title</th>\n",
       "      <th>Full_citation</th>\n",
       "      <th>Journal</th>\n",
       "      <th>year</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torre LA, Bray F, Siegel RL, Ferlay J, Lortet-...</td>\n",
       "      <td>Global cancer statistics, 2012...</td>\n",
       "      <td>CA Cancer J Clin. 2015 Mar;65(2):87-108. doi: ...</td>\n",
       "      <td>CA Cancer J Clin</td>\n",
       "      <td>2015</td>\n",
       "      <td>PMID: 25651787</td>\n",
       "      <td>cancer, epidemiology, healthdisparities, incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morrison AH, Byrne KT, Vonderheide RH.</td>\n",
       "      <td>Immunotherapy and Prevention o...</td>\n",
       "      <td>Trends Cancer. 2018 Jun;4(6):418-428. doi: 10....</td>\n",
       "      <td>Trends Cancer</td>\n",
       "      <td>2018</td>\n",
       "      <td>PMID: 29860986</td>\n",
       "      <td>immunotherapy, pancreaticcancer, preventionvac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goral V.</td>\n",
       "      <td>Pancreatic Cancer: Pathogenesi...</td>\n",
       "      <td>Asian Pac J Cancer Prev. 2015;16(14):5619-24. ...</td>\n",
       "      <td>Asian Pac J Cancer Prev</td>\n",
       "      <td>2015</td>\n",
       "      <td>PMID: 26320426</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wang JJ, Lei KF, Han F.</td>\n",
       "      <td>Tumor microenvironment: recent...</td>\n",
       "      <td>Eur Rev Med Pharmacol Sci. 2018 Jun;22(12):385...</td>\n",
       "      <td>Eur Rev Med Pharmacol Sci</td>\n",
       "      <td>2018</td>\n",
       "      <td>PMID: 29949179</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Torre LA, Siegel RL, Ward EM, Jemal A.</td>\n",
       "      <td>Global Cancer Incidence and Mo...</td>\n",
       "      <td>Cancer Epidemiol Biomarkers Prev. 2016 Jan;25(...</td>\n",
       "      <td>Cancer Epidemiol Biomarkers Prev</td>\n",
       "      <td>2016</td>\n",
       "      <td>PMID: 26667886</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Authors  \\\n",
       "0  Torre LA, Bray F, Siegel RL, Ferlay J, Lortet-...   \n",
       "1             Morrison AH, Byrne KT, Vonderheide RH.   \n",
       "2                                           Goral V.   \n",
       "3                            Wang JJ, Lei KF, Han F.   \n",
       "4             Torre LA, Siegel RL, Ward EM, Jemal A.   \n",
       "\n",
       "                                               title  \\\n",
       "0                  Global cancer statistics, 2012...   \n",
       "1                  Immunotherapy and Prevention o...   \n",
       "2                  Pancreatic Cancer: Pathogenesi...   \n",
       "3                  Tumor microenvironment: recent...   \n",
       "4                  Global Cancer Incidence and Mo...   \n",
       "\n",
       "                                       Full_citation  \\\n",
       "0  CA Cancer J Clin. 2015 Mar;65(2):87-108. doi: ...   \n",
       "1  Trends Cancer. 2018 Jun;4(6):418-428. doi: 10....   \n",
       "2  Asian Pac J Cancer Prev. 2015;16(14):5619-24. ...   \n",
       "3  Eur Rev Med Pharmacol Sci. 2018 Jun;22(12):385...   \n",
       "4  Cancer Epidemiol Biomarkers Prev. 2016 Jan;25(...   \n",
       "\n",
       "                            Journal  year            PMID  \\\n",
       "0                  CA Cancer J Clin  2015  PMID: 25651787   \n",
       "1                     Trends Cancer  2018  PMID: 29860986   \n",
       "2           Asian Pac J Cancer Prev  2015  PMID: 26320426   \n",
       "3         Eur Rev Med Pharmacol Sci  2018  PMID: 29949179   \n",
       "4  Cancer Epidemiol Biomarkers Prev  2016  PMID: 26667886   \n",
       "\n",
       "                                            Keywords  \n",
       "0  cancer, epidemiology, healthdisparities, incid...  \n",
       "1  immunotherapy, pancreaticcancer, preventionvac...  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cancers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the columns we can take title and Keywords as features, and the journal as target.  \n",
    "\n",
    "The journals can be encoded using either one-hot or label-encoding.  \n",
    "\n",
    "**Title**: Tokenization, followed by the removal of stopwords and Lemmatization.\n",
    "\n",
    "**Keywords**: Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization and Lemmatization of title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop =set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       global cancer statistics, 2012...\n",
       "1                       immunotherapy and prevention o...\n",
       "2                       pancreatic cancer: pathogenesi...\n",
       "3                       tumor microenvironment: recent...\n",
       "4                       global cancer incidence and mo...\n",
       "                              ...                        \n",
       "9995                    extracellular vesicles and mic...\n",
       "9996                    dexamethasone modified by gamm...\n",
       "9997                    evaluating the utility of comp...\n",
       "9998                    over-expression of long noncod...\n",
       "9999                    metabolic reprogramming and ca...\n",
       "Name: title, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title']=df['title'].str.lower()\n",
    "df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "df['title_lemmatized'] = df['title'].str.lower().apply(lemmatize_text)\n",
    "df['title_words']=df['title_lemmatized'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           global cancer statistics 2012\n",
       "1              immunotherapy prevention pancreatic cancer\n",
       "2                pancreatic cancer pathogenesis diagnosis\n",
       "3       tumor microenvironment recent advance various ...\n",
       "4       global cancer incidence mortality rate trendsa...\n",
       "                              ...                        \n",
       "9995    extracellular vesicle micrornas role tumorigen...\n",
       "9996    dexamethasone modified gammairradiation novel ...\n",
       "9997    evaluating utility computed tomography chest g...\n",
       "9998    overexpression long noncoding rna bancr inhibi...\n",
       "9999           metabolic reprogramming cancer progression\n",
       "Name: title_words, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_words'] = df['title_words'].apply(lambda x : \" \".join(x))\n",
    "df['title_words']=df['title_words'].str.replace(r\"[^ A-Za-z0-9]\",'')\n",
    "df['title_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       cancer epidemiology healthdisparities incidenc...\n",
       "1       immunotherapy pancreaticcancer preventionvaccines\n",
       "2                                                    none\n",
       "3                                                    none\n",
       "4                                                    none\n",
       "                              ...                        \n",
       "9995    cancerstemcells exosomes extracellularvesicles...\n",
       "9996                                                 none\n",
       "9997                                                 none\n",
       "9998        bancr bladdercancer lncrnas therapeutictarget\n",
       "9999                                                 none\n",
       "Name: keyword_lemmatized, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword_lemmatized'] = df['Keywords'].str.lower().apply(lemmatize_text)\n",
    "df['keyword_lemmatized'] =df['keyword_lemmatized'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['keyword_lemmatized'] = df['keyword_lemmatized'].apply(lambda x : \" \".join(x))\n",
    "df['keyword_lemmatized'] = df['keyword_lemmatized'].str.replace(r\"[^ A-Za-z0-9]\",'')\n",
    "df['keyword_lemmatized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(df['Journal'])\n",
    "df['target']=le.transform(df['Journal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.sample(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_1=vectorizer.fit_transform(df1['keyword_lemmatized'] + df1['title_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "y = df1['target']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_1,y,test_size=0.25,random_state=100)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pd.DataFrame(clf.predict_proba(X_test), columns=clf.classes_)\n",
    "target_cols = prob.columns\n",
    "target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(prob)[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Post prediction processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_lst = df['Journal'].to_list()\n",
    "target_lst = df['target'].to_list()\n",
    "d = dict(zip(target_lst,journal_lst))\n",
    "final_preds = []\n",
    "final_1 = np.argsort(preds, axis=1)\n",
    "final_2 = np.fliplr(final_1)\n",
    "for ind, pred in enumerate(final_2):\n",
    "  top_picks = target_cols[pred]\n",
    "  journal_name = []\n",
    "  for i in top_picks[:5]:\n",
    "    journal_name.append(d.get(i))\n",
    "  final_preds.append(\", \".join(journal_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_journal_name = []\n",
    "for i in y_test:\n",
    "  ori_journal_name.append(d.get(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "acc = 0\n",
    "for i in ori_journal_name:\n",
    "  if i in final_preds[counter]:\n",
    "    acc += 1\n",
    "  counter += 1\n",
    "print(acc/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['title'] = df.iloc[y_test.index]['title']\n",
    "output['keywords'] = df.iloc[y_test.index]['Keywords']\n",
    "output['Journals'] = final_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualisation of the final output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
